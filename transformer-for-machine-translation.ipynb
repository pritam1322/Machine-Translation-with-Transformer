{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-11T17:20:46.537908Z",
     "iopub.status.busy": "2021-01-11T17:20:46.537068Z",
     "iopub.status.idle": "2021-01-11T17:20:46.540403Z",
     "shell.execute_reply": "2021-01-11T17:20:46.539725Z"
    },
    "papermill": {
     "duration": 0.022893,
     "end_time": "2021-01-11T17:20:46.540511",
     "exception": false,
     "start_time": "2021-01-11T17:20:46.517618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-11T17:20:46.567716Z",
     "iopub.status.busy": "2021-01-11T17:20:46.566997Z",
     "iopub.status.idle": "2021-01-11T17:20:51.016540Z",
     "shell.execute_reply": "2021-01-11T17:20:51.015985Z"
    },
    "papermill": {
     "duration": 4.464668,
     "end_time": "2021-01-11T17:20:51.016651",
     "exception": false,
     "start_time": "2021-01-11T17:20:46.551983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import re\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import spacy\n",
    "from torchtext.datasets import Multi30k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T17:20:51.045881Z",
     "iopub.status.busy": "2021-01-11T17:20:51.044908Z",
     "iopub.status.idle": "2021-01-11T17:21:09.038749Z",
     "shell.execute_reply": "2021-01-11T17:21:09.037637Z"
    },
    "papermill": {
     "duration": 18.010334,
     "end_time": "2021-01-11T17:21:09.038876",
     "exception": false,
     "start_time": "2021-01-11T17:20:51.028542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting de_core_news_sm==2.3.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.3.0/de_core_news_sm-2.3.0.tar.gz (14.9 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 14.9 MB 2.9 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from de_core_news_sm==2.3.0) (2.3.4)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.0.5)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.8.0)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.18.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.5)\r\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.0)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.0.5)\r\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.1.3)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.23.0)\r\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.5)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.7.4)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (4.45.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (7.4.3)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.18.5)\r\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.1.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.1.0)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.5)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2020.12.5)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.0.4)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.9)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.25.9)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.0.5)\r\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.5)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.18.5)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.7.4)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.5)\r\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.0)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.8.0)\r\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.1.3)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (4.45.0)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.0.5)\r\n",
      "Building wheels for collected packages: de-core-news-sm\r\n",
      "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.3.0-py3-none-any.whl size=14907580 sha256=eabc9c265f197408126f7351f1546b86cdb217d98fc26bb9964818348d12b962\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-cr_bb3k1/wheels/75/30/c3/ea1c6002eede7f49c8ab017ce62a2981a87b1cd39fab6e6a65\r\n",
      "Successfully built de-core-news-sm\r\n",
      "Installing collected packages: de-core-news-sm\r\n",
      "Successfully installed de-core-news-sm-2.3.0\r\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the model via spacy.load('de_core_news_sm')\r\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\r\n",
      "/opt/conda/lib/python3.7/site-packages/de_core_news_sm -->\r\n",
      "/opt/conda/lib/python3.7/site-packages/spacy/data/de\r\n",
      "You can now load the model via spacy.load('de')\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m spacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T17:21:09.098035Z",
     "iopub.status.busy": "2021-01-11T17:21:09.097179Z",
     "iopub.status.idle": "2021-01-11T17:21:12.067486Z",
     "shell.execute_reply": "2021-01-11T17:21:12.066560Z"
    },
    "papermill": {
     "duration": 3.002475,
     "end_time": "2021-01-11T17:21:12.067606",
     "exception": false,
     "start_time": "2021-01-11T17:21:09.065131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'Pain']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_ger = spacy.load(\"de\")\n",
    "spacy_eng = spacy.load(\"en\")\n",
    "def tokenize_ger(text):\n",
    "    return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
    "\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]\n",
    "t=tokenize_eng(\"I am Pain \")\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T17:21:12.122595Z",
     "iopub.status.busy": "2021-01-11T17:21:12.121877Z",
     "iopub.status.idle": "2021-01-11T17:21:12.129873Z",
     "shell.execute_reply": "2021-01-11T17:21:12.129217Z"
    },
    "papermill": {
     "duration": 0.037289,
     "end_time": "2021-01-11T17:21:12.130020",
     "exception": false,
     "start_time": "2021-01-11T17:21:12.092731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import Field\n",
    "\n",
    "german = Field(tokenize=tokenize_ger, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "\n",
    "english = Field(\n",
    "    tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T17:21:12.184752Z",
     "iopub.status.busy": "2021-01-11T17:21:12.183904Z",
     "iopub.status.idle": "2021-01-11T17:21:22.121301Z",
     "shell.execute_reply": "2021-01-11T17:21:22.120504Z"
    },
    "papermill": {
     "duration": 9.966328,
     "end_time": "2021-01-11T17:21:22.121471",
     "exception": false,
     "start_time": "2021-01-11T17:21:12.155143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading training.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:00<00:00, 1.44MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading validation.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 257kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading mmt_task1_test2016.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 237kB/s]\n",
      "/opt/conda/lib/python3.7/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(\n",
    "    exts=(\".de\", \".en\"), fields=(german, english)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T17:21:22.249764Z",
     "iopub.status.busy": "2021-01-11T17:21:22.239435Z",
     "iopub.status.idle": "2021-01-11T17:21:22.561116Z",
     "shell.execute_reply": "2021-01-11T17:21:22.560590Z"
    },
    "papermill": {
     "duration": 0.382541,
     "end_time": "2021-01-11T17:21:22.561243",
     "exception": false,
     "start_time": "2021-01-11T17:21:22.178702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "english.build_vocab(train_data, max_size=10000, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T17:21:22.647207Z",
     "iopub.status.busy": "2021-01-11T17:21:22.645213Z",
     "iopub.status.idle": "2021-01-11T17:21:22.647905Z",
     "shell.execute_reply": "2021-01-11T17:21:22.648395Z"
    },
    "papermill": {
     "duration": 0.0543,
     "end_time": "2021-01-11T17:21:22.648510",
     "exception": false,
     "start_time": "2021-01-11T17:21:22.594210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                embedding_size,\n",
    "                src_vocab_size,\n",
    "                trg_vocab_size,\n",
    "                src_pad_idx,\n",
    "                num_heads,\n",
    "                num_encoder_layers,\n",
    "                num_edecoder_layers,\n",
    "                forward_expansion,\n",
    "                dropout,\n",
    "                max_len,\n",
    "                device\n",
    "                ):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size )\n",
    "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size )\n",
    "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        \n",
    "        self.device = device\n",
    "        self.transformer = nn.Transformer(\n",
    "            embedding_size,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "        )\n",
    "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "    \n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = src.transpose(0,1) == self.src_pad_idx\n",
    "        return src_mask.to(self.device)\n",
    "    def forward(self, src, trg):\n",
    "        src_seq_length, N = src.shape\n",
    "        trg_seq_length, N = trg.shape\n",
    "\n",
    "        src_positions = (\n",
    "            torch.arange(0, src_seq_length)\n",
    "            .unsqueeze(1)\n",
    "            .expand(src_seq_length, N)\n",
    "            .to(self.device)\n",
    "        )\n",
    "\n",
    "        trg_positions = (\n",
    "            torch.arange(0, trg_seq_length)\n",
    "            .unsqueeze(1)\n",
    "            .expand(trg_seq_length, N)\n",
    "            .to(self.device)\n",
    "        )\n",
    "\n",
    "        embed_src = self.dropout(\n",
    "            (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n",
    "        )\n",
    "        embed_trg = self.dropout(\n",
    "            (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\n",
    "        )\n",
    "\n",
    "        src_padding_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(\n",
    "            self.device\n",
    "        )\n",
    "\n",
    "        out = self.transformer(\n",
    "            embed_src,\n",
    "            embed_trg,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_mask=trg_mask,\n",
    "        )\n",
    "        out = self.fc_out(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T17:21:22.735737Z",
     "iopub.status.busy": "2021-01-11T17:21:22.733867Z",
     "iopub.status.idle": "2021-01-11T17:21:22.736452Z",
     "shell.execute_reply": "2021-01-11T17:21:22.736934Z"
    },
    "papermill": {
     "duration": 0.055184,
     "end_time": "2021-01-11T17:21:22.737045",
     "exception": false,
     "start_time": "2021-01-11T17:21:22.681861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import spacy\n",
    "from torchtext.data.metrics import bleu_score\n",
    "import sys\n",
    "\n",
    "\n",
    "def translate_sentence(model, sentence, german, english, device, max_length=50):\n",
    "    # Load german tokenizer\n",
    "    spacy_ger = spacy.load(\"de\")\n",
    "\n",
    "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "    if type(sentence) == str:\n",
    "        tokens = [token.text.lower() for token in spacy_ger(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "    tokens.insert(0, german.init_token)\n",
    "    tokens.append(german.eos_token)\n",
    "\n",
    "    # Go through each german token and convert to an index\n",
    "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
    "    for i in range(max_length):\n",
    "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(sentence_tensor, trg_tensor)\n",
    "\n",
    "        best_guess = output.argmax(2)[-1, :].item()\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        if best_guess == english.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
    "    # remove start token\n",
    "    return translated_sentence[1:]\n",
    "\n",
    "\n",
    "def bleu(data, model, german, english, device):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "\n",
    "    for example in data:\n",
    "        src = vars(example)[\"src\"]\n",
    "        trg = vars(example)[\"trg\"]\n",
    "\n",
    "        prediction = translate_sentence(model, src, german, english, device)\n",
    "        prediction = prediction[:-1]  # remove <eos> token\n",
    "\n",
    "        targets.append([trg])\n",
    "        outputs.append(prediction)\n",
    "\n",
    "    return bleu_score(outputs, targets)\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T17:21:23.175622Z",
     "iopub.status.busy": "2021-01-11T17:21:23.174676Z",
     "iopub.status.idle": "2021-01-11T17:21:23.178122Z",
     "shell.execute_reply": "2021-01-11T17:21:23.178748Z"
    },
    "papermill": {
     "duration": 0.407066,
     "end_time": "2021-01-11T17:21:23.178939",
     "exception": false,
     "start_time": "2021-01-11T17:21:22.771873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "load_model = True\n",
    "save_model = True\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T17:21:23.256510Z",
     "iopub.status.busy": "2021-01-11T17:21:23.255614Z",
     "iopub.status.idle": "2021-01-11T17:21:28.156323Z",
     "shell.execute_reply": "2021-01-11T17:21:28.157049Z"
    },
    "papermill": {
     "duration": 4.944564,
     "end_time": "2021-01-11T17:21:28.157209",
     "exception": false,
     "start_time": "2021-01-11T17:21:23.212645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchtext.data import Field, BucketIterator\n",
    "# Training hyperparameters\n",
    "num_epochs = 5\n",
    "learning_rate = 3e-4\n",
    "batch_size = 32\n",
    "\n",
    "# Model hyperparameters\n",
    "src_vocab_size = len(german.vocab)\n",
    "trg_vocab_size = len(english.vocab)\n",
    "embedding_size = 512\n",
    "num_heads = 8\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "dropout = 0.10\n",
    "max_len = 100\n",
    "forward_expansion = 4\n",
    "src_pad_idx = english.vocab.stoi[\"<pad>\"]\n",
    "\n",
    "# Tensorboard to get nice loss plot\n",
    "writer = SummaryWriter(\"runs/loss_plot\")\n",
    "step = 0\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=batch_size,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.src),\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-11T17:21:28.250417Z",
     "iopub.status.busy": "2021-01-11T17:21:28.244320Z",
     "iopub.status.idle": "2021-01-11T17:28:01.668835Z",
     "shell.execute_reply": "2021-01-11T17:28:01.669828Z"
    },
    "papermill": {
     "duration": 393.478072,
     "end_time": "2021-01-11T17:28:01.670054",
     "exception": false,
     "start_time": "2021-01-11T17:21:28.191982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / 5]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['take', 'push', 'school', 'push', 'take', 'wooden', 'hit', 'francisco', 'foods', 'push', 'wooden', 'push', 'take', 'push', 'take', 'push', 'take', 'push', 'wooden', 'push', 'take', 'runners', 'wooden', 'being', 'push', 'wooden', 'hit', 'being', 'push', 'take', 'push', 'take', 'push', 'wooden', 'wooden', 'hit', 'being', 'couples', 'push', 'take', 'quad', 'take', 'quad', 'take', 'quad', 'take', 'push', 'take', 'quad', 'push']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 / 5]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'horse', 'walks', 'under', 'a', 'boat', 'next', 'to', 'a', 'boat', '.', '<eos>']\n",
      "[Epoch 2 / 5]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'horse', 'walks', 'under', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n",
      "[Epoch 3 / 5]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'horse', 'walks', 'under', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n",
      "[Epoch 4 / 5]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'horse', 'walks', 'under', 'a', 'bridge', 'next', 'to', 'a', 'boat', '.', '<eos>']\n",
      "Bleu score 27.86\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(\n",
    "                embedding_size,\n",
    "                src_vocab_size,\n",
    "                trg_vocab_size,\n",
    "                src_pad_idx,\n",
    "                num_heads,\n",
    "                num_encoder_layers,\n",
    "                num_decoder_layers,\n",
    "                forward_expansion,\n",
    "                dropout,\n",
    "                max_len,\n",
    "                device,).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "optimizer, factor = 0.1, patience = 10, verbose = True)\n",
    "\n",
    "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "\n",
    "sentence = \"ein pferd geht unter einer brücke neben einem boot.\"\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "\n",
    "    if save_model:\n",
    "        checkpoint = {\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "        }\n",
    "        save_checkpoint(checkpoint)\n",
    "\n",
    "    model.eval()\n",
    "    translated_sentence = translate_sentence(\n",
    "        model, sentence, german, english, device, max_length=50\n",
    "    )\n",
    "\n",
    "    print(f\"Translated example sentence: \\n {translated_sentence}\")\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for batch_idx, batch in enumerate(train_iterator):\n",
    "        # Get input and targets and get to cuda\n",
    "        inp_data = batch.src.to(device)\n",
    "        target = batch.trg.to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(inp_data, target[:-1, :])\n",
    "\n",
    "        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
    "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
    "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
    "        # way that we have output_words * batch_size that we want to send in into\n",
    "        # our cost function, so we need to do some reshapin.\n",
    "        # Let's also remove the start token while we're at it\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "        # within a healthy range\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # plot to tensorboard\n",
    "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "        step += 1\n",
    "\n",
    "    mean_loss = sum(losses) / len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "# running on entire test data takes a while\n",
    "score = bleu(test_data[1:100], model, german, english, device)\n",
    "print(f\"Bleu score {score * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.04297,
     "end_time": "2021-01-11T17:28:01.758334",
     "exception": false,
     "start_time": "2021-01-11T17:28:01.715364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.05234,
     "end_time": "2021-01-11T17:28:01.856936",
     "exception": false,
     "start_time": "2021-01-11T17:28:01.804596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.041887,
     "end_time": "2021-01-11T17:28:01.942415",
     "exception": false,
     "start_time": "2021-01-11T17:28:01.900528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 440.869449,
   "end_time": "2021-01-11T17:28:03.119871",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-11T17:20:42.250422",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
